{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24aeb17d40f67591",
   "metadata": {},
   "source": [
    "### Anthropic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SetUp library\n",
    "%pip install -U anthropic pydantic python-dotenv\n",
    "\n",
    "import os, sys\n",
    "import anthropic\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"anthropic SDK:\", anthropic.__version__)\n",
    "print(\"Kernel:\", sys.executable)\n",
    "print(\"Has ANTHROPIC_API_KEY?:\", \"ANTHROPIC_API_KEY\" in os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd637100865fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check API_KEY\n",
    "import os\n",
    "\n",
    "print(\"ANTHROPIC_API_KEY:\", os.environ.get(\"ANTHROPIC_API_KEY\", \"Not set\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bfa0ec3c1b3ad",
   "metadata": {},
   "source": [
    "### (1) messages.create：一般的な応答生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3113420afcad7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"以下の要件で簡潔に回答してください：\n",
    "- 対象: Python学習者\n",
    "- トピック: Anthropic APIのはじめ方\n",
    "- 箇条書き3つ\n",
    "\"\"\"\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "MODEL = \"claude-3-5-haiku-20241022\"\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=MODEL,\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content[0].text)  # テキスト抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b616f9e946fef",
   "metadata": {},
   "source": [
    "#### (2) 構造化出力（Pydantic with JSON Schema）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ceac3c38607d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 構造化出力（Pydantic）\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from anthropic import Anthropic\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json, os\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "MODEL = os.getenv(\"ANTHROPIC_MODEL\", \"claude-3-5-haiku-20241022\")\n",
    "\n",
    "class TodoItem(BaseModel):\n",
    "    title: str = Field(..., description=\"やることのタイトル\")\n",
    "    priority: int = Field(..., ge=1, le=5, description=\"1(低)〜5(高)\")\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "\n",
    "class TodoPlan(BaseModel):\n",
    "    owner: str\n",
    "    items: List[TodoItem]\n",
    "\n",
    "instruction = \"あなたは秘書です。日本語で、学習計画のToDoを構造化して返してください。\"\n",
    "user_text = \"明日はAnthropic APIを勉強、週末はQdrantを触る。優先度高いのは明日の学習。タグは['api','vector']\"\n",
    "\n",
    "# JSON Schemaを生成\n",
    "def to_json_schema(model_cls):\n",
    "    if hasattr(model_cls, \"model_json_schema\"):\n",
    "        return model_cls.model_json_schema()\n",
    "    return model_cls.schema()\n",
    "\n",
    "schema = to_json_schema(TodoPlan)\n",
    "\n",
    "# Anthropic APIで構造化出力を生成\n",
    "response = client.messages.create(\n",
    "    model=MODEL,\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"{instruction}\n",
    "            \n",
    "ユーザー入力: {user_text}\n",
    "\n",
    "以下のJSONスキーマに厳密に従って、有効なJSONのみを出力してください：\n",
    "{json.dumps(schema, ensure_ascii=False, indent=2)}\n",
    "\n",
    "必ずJSONのみを返し、説明やマークダウンは一切含めないでください。\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# JSONをパースしてPydanticモデルで検証\n",
    "try:\n",
    "    json_text = response.content[0].text.strip()\n",
    "    # マークダウンのコードブロックがある場合は除去\n",
    "    if json_text.startswith('```json'):\n",
    "        json_text = json_text.split('```json')[1].split('```')[0].strip()\n",
    "    elif json_text.startswith('```'):\n",
    "        json_text = json_text.split('```')[1].split('```')[0].strip()\n",
    "    \n",
    "    data = json.loads(json_text)\n",
    "    parsed_plan = TodoPlan.model_validate(data)\n",
    "    print(parsed_plan)\n",
    "except (json.JSONDecodeError, ValueError) as e:\n",
    "    print(f\"JSONパースエラー: {e}\")\n",
    "    print(f\"生の応答: {response.content[0].text}\")\n",
    "except Exception as e:\n",
    "    print(f\"バリデーションエラー: {e}\")\n",
    "    print(f\"パースされたデータ: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a2cadfa5361c32",
   "metadata": {},
   "source": [
    "### (3) 注意：音声機能について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775076638db71080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic APIには現在、音声生成機能（TTS）は含まれていません\n",
    "# 音声機能が必要な場合は、以下のような代替手段を検討してください：\n",
    "# 1. Google Cloud Text-to-Speech API\n",
    "# 2. Azure Cognitive Services Speech\n",
    "# 3. Amazon Polly\n",
    "# 4. ElevenLabs API\n",
    "\n",
    "print(\"注意: Anthropic APIには音声生成機能は含まれていません。\")\n",
    "print(\"音声機能が必要な場合は、専用の音声サービスを利用してください。\")\n",
    "print(\"\")\n",
    "print(\"例: Google Cloud Text-to-Speech APIの使用例\")\n",
    "print(\"pip install google-cloud-texttospeech\")\n",
    "print(\"\")\n",
    "print(\"from google.cloud import texttospeech\")\n",
    "print(\"client = texttospeech.TextToSpeechClient()\")\n",
    "print(\"# ... 音声生成処理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999422057e2fc3cb",
   "metadata": {},
   "source": [
    "### (4) 注意：音声認識機能について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d6ba8d289e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic APIには現在、音声認識機能（STT）は含まれていません\n",
    "# 音声認識が必要な場合は、以下のような代替手段を検討してください：\n",
    "# 1. Google Cloud Speech-to-Text API\n",
    "# 2. Azure Cognitive Services Speech\n",
    "# 3. Amazon Transcribe\n",
    "# 4. OpenAI Whisper API\n",
    "\n",
    "print(\"注意: Anthropic APIには音声認識機能は含まれていません。\")\n",
    "print(\"音声認識が必要な場合は、専用の音声認識サービスを利用してください。\")\n",
    "print(\"\")\n",
    "print(\"例: Google Cloud Speech-to-Text APIの使用例\")\n",
    "print(\"pip install google-cloud-speech\")\n",
    "print(\"\")\n",
    "print(\"from google.cloud import speech\")\n",
    "print(\"client = speech.SpeechClient()\")\n",
    "print(\"# ... 音声認識処理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7feb09d78bba28",
   "metadata": {},
   "source": [
    "### (5) 注意：音声翻訳機能について"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafff49017fb90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic APIには現在、音声翻訳機能は含まれていません\n",
    "# 音声翻訳が必要な場合は、以下のような代替手段を検討してください：\n",
    "# 1. OpenAI Whisper API (音声→テキスト翻訳)\n",
    "# 2. Google Translate API + 音声認識API\n",
    "# 3. Azure Translator + 音声認識API\n",
    "\n",
    "print(\"注意: Anthropic APIには音声翻訳機能は含まれていません。\")\n",
    "print(\"音声翻訳が必要な場合は、専用のサービスを利用してください。\")\n",
    "print(\"\")\n",
    "print(\"例: OpenAI Whisper APIで音声翻訳を行う場合\")\n",
    "print(\"pip install openai\")\n",
    "print(\"\")\n",
    "print(\"import openai\")\n",
    "print(\"client = openai.OpenAI()\")\n",
    "print(\"with open('audio.mp3', 'rb') as f:\")\n",
    "print(\"    translation = client.audio.translations.create(\")\n",
    "print(\"        model='whisper-1', file=f, response_format='text')\")\n",
    "print(\"    print(translation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f5d237c7573cc",
   "metadata": {},
   "source": [
    "### (6) 画像処理：Claude Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0f7312d2a529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude Vision - 画像解析機能\n",
    "# 注意: Anthropic APIには画像生成機能はありませんが、画像解析機能があります\n",
    "import base64\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "# 画像生成は外部サービスを使用する必要があります\n",
    "print(\"注意: Anthropic APIには画像生成機能は含まれていません。\")\n",
    "print(\"画像生成が必要な場合は、以下のようなサービスを利用してください：\")\n",
    "print(\"- DALL-E (OpenAI)\")\n",
    "print(\"- Midjourney\")\n",
    "print(\"- Stable Diffusion\")\n",
    "print(\"- Adobe Firefly\")\n",
    "print(\"\")\n",
    "\n",
    "# 代わりに、画像解析の例を示します\n",
    "print(\"Claude Vision - 画像解析の例:\")\n",
    "print(\"\")\n",
    "\n",
    "# サンプル画像ファイル（5MB制限内のファイルを使用）\n",
    "sample_image_path = \"images/bmetal.png\"  # 134KB - 5MB制限内\n",
    "\n",
    "# 画像解析のサンプルコード:\n",
    "try:\n",
    "    with open(sample_image_path, 'rb') as f:\n",
    "        image_data = base64.b64encode(f.read()).decode('utf-8')\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241125\",  # より新しいモデルを使用\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"この画像について詳しく説明してください。\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": image_data\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(response.content[0].text)\n",
    "except FileNotFoundError:\n",
    "    print(\"画像ファイルが見つかりません。適切な画像パスを指定してください。\")\n",
    "except Exception as e:\n",
    "    print(f\"エラーが発生しました: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbcdaac6288cea5",
   "metadata": {},
   "source": [
    "### (7) messages.create：詳細なメッセージ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42423214cf4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.messages.create(\n",
    "    model=MODEL,\n",
    "    max_tokens=1000,\n",
    "    system=\"あなたは有能なPythonメンターです。\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Anthropic APIでJSONの構造化出力を行うには？\"},\n",
    "    ],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}