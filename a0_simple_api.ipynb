{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Anthropic API",
   "id": "24aeb17d40f67591"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-29T11:30:37.649745Z",
     "start_time": "2025-08-29T11:30:36.032631Z"
    }
   },
   "source": "# SetUp library\n%pip install -U anthropic pydantic python-dotenv\n\nimport os, sys\nimport anthropic\n\nprint(\"Python:\", sys.version)\nprint(\"anthropic SDK:\", anthropic.__version__)\nprint(\"Kernel:\", sys.executable)\nprint(\"Has ANTHROPIC_API_KEY?:\", \"ANTHROPIC_API_KEY\" in os.environ)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T11:30:39.772303Z",
     "start_time": "2025-08-29T11:30:39.769832Z"
    }
   },
   "cell_type": "code",
   "source": "# Check API_KEY\nimport os\n\nprint(\"ANTHROPIC_API_KEY:\", os.environ.get(\"ANTHROPIC_API_KEY\", \"Not set\"))",
   "id": "36bd637100865fb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (1) messages.create：一般的な応答生成",
   "id": "646bfa0ec3c1b3ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T11:30:55.281603Z",
     "start_time": "2025-08-29T11:30:43.288755Z"
    }
   },
   "cell_type": "code",
   "source": "prompt = \"\"\"以下の要件で簡潔に回答してください：\n- 対象: Python学習者\n- トピック: Anthropic APIのはじめ方\n- 箇条書き3つ\n\"\"\"\nfrom anthropic import Anthropic\n\nclient = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n\nMODEL = \"claude-3-5-haiku-20241022\"\n\nresponse = client.messages.create(\n    model=MODEL,\n    max_tokens=1000,\n    messages=[\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n)\n\nprint(response.content[0].text)  # テキスト抽出",
   "id": "3113420afcad7f01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (2) 構造化出力（Pydantic with JSON Schema）",
   "id": "c47b616f9e946fef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T11:31:09.476795Z",
     "start_time": "2025-08-29T11:30:58.767330Z"
    }
   },
   "cell_type": "code",
   "source": "# 構造化出力（Pydantic）\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport json, os\n\nclient = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\nMODEL = os.getenv(\"ANTHROPIC_MODEL\", \"claude-3-5-haiku-20241022\")\n\nclass TodoItem(BaseModel):\n    title: str = Field(..., description=\"やることのタイトル\")\n    priority: int = Field(..., ge=1, le=5, description=\"1(低)〜5(高)\")\n    tags: List[str] = Field(default_factory=list)\n\nclass TodoPlan(BaseModel):\n    owner: str\n    items: List[TodoItem]\n\ninstruction = \"あなたは秘書です。日本語で、学習計画のToDoを構造化して返してください。\"\nuser_text = \"明日はAnthropic APIを勉強、週末はQdrantを触る。優先度高いのは明日の学習。タグは['api','vector']\"\n\n# JSON Schemaを生成\ndef to_json_schema(model_cls):\n    if hasattr(model_cls, \"model_json_schema\"):\n        return model_cls.model_json_schema()\n    return model_cls.schema()\n\nschema = to_json_schema(TodoPlan)\n\n# Anthropic APIで構造化出力を生成\nresponse = client.messages.create(\n    model=MODEL,\n    max_tokens=1000,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": f\"\"\"{instruction}\n            \nユーザー入力: {user_text}\n\n以下のJSONスキーマに厳密に従って、有効なJSONのみを出力してください：\n{json.dumps(schema, ensure_ascii=False, indent=2)}\n\n必ずJSONのみを返し、説明やマークダウンは一切含めないでください。\"\"\"\n        }\n    ],\n    temperature=0\n)\n\n# JSONをパースしてPydanticモデルで検証\ntry:\n    json_text = response.content[0].text.strip()\n    # マークダウンのコードブロックがある場合は除去\n    if json_text.startswith('```json'):\n        json_text = json_text.split('```json')[1].split('```')[0].strip()\n    elif json_text.startswith('```'):\n        json_text = json_text.split('```')[1].split('```')[0].strip()\n    \n    data = json.loads(json_text)\n    parsed_plan = TodoPlan.model_validate(data)\n    print(parsed_plan)\nexcept (json.JSONDecodeError, ValueError) as e:\n    print(f\"JSONパースエラー: {e}\")\n    print(f\"生の応答: {response.content[0].text}\")\nexcept Exception as e:\n    print(f\"バリデーションエラー: {e}\")\n    print(f\"パースされたデータ: {data}\")",
   "id": "c4ceac3c38607d1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (3) 注意：音声機能について",
   "id": "73a2cadfa5361c32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T11:31:15.549019Z",
     "start_time": "2025-08-29T11:31:13.779712Z"
    }
   },
   "cell_type": "code",
   "source": "# Anthropic APIには現在、音声生成機能（TTS）は含まれていません\n# 音声機能が必要な場合は、以下のような代替手段を検討してください：\n# 1. Google Cloud Text-to-Speech API\n# 2. Azure Cognitive Services Speech\n# 3. Amazon Polly\n# 4. ElevenLabs API\n\nprint(\"注意: Anthropic APIには音声生成機能は含まれていません。\")\nprint(\"音声機能が必要な場合は、専用の音声サービスを利用してください。\")\nprint(\"\")\nprint(\"例: Google Cloud Text-to-Speech APIの使用例\")\nprint(\"pip install google-cloud-texttospeech\")\nprint(\"\")\nprint(\"from google.cloud import texttospeech\")\nprint(\"client = texttospeech.TextToSpeechClient()\")\nprint(\"# ... 音声生成処理\")",
   "id": "775076638db71080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (4) 注意：音声認識機能について",
   "id": "999422057e2fc3cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T11:31:24.300475Z",
     "start_time": "2025-08-29T11:31:21.471094Z"
    }
   },
   "cell_type": "code",
   "source": "# Anthropic APIには現在、音声認識機能（STT）は含まれていません\n# 音声認識が必要な場合は、以下のような代替手段を検討してください：\n# 1. Google Cloud Speech-to-Text API\n# 2. Azure Cognitive Services Speech\n# 3. Amazon Transcribe\n# 4. OpenAI Whisper API\n\nprint(\"注意: Anthropic APIには音声認識機能は含まれていません。\")\nprint(\"音声認識が必要な場合は、専用の音声認識サービスを利用してください。\")\nprint(\"\")\nprint(\"例: Google Cloud Speech-to-Text APIの使用例\")\nprint(\"pip install google-cloud-speech\")\nprint(\"\")\nprint(\"from google.cloud import speech\")\nprint(\"client = speech.SpeechClient()\")\nprint(\"# ... 音声認識処理\")",
   "id": "3c3d6ba8d289e135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (5) 注意：音声翻訳機能について",
   "id": "ac7feb09d78bba28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T12:02:43.908499Z",
     "start_time": "2025-08-29T12:02:42.090963Z"
    }
   },
   "cell_type": "code",
   "source": "# Anthropic APIには現在、音声翻訳機能は含まれていません\n# 音声翻訳が必要な場合は、以下のような代替手段を検討してください：\n# 1. OpenAI Whisper API (音声→テキスト翻訳)\n# 2. Google Translate API + 音声認識API\n# 3. Azure Translator + 音声認識API\n\nprint(\"注意: Anthropic APIには音声翻訳機能は含まれていません。\")\nprint(\"音声翻訳が必要な場合は、専用のサービスを利用してください。\")\nprint(\"\")\nprint(\"例: OpenAI Whisper APIで音声翻訳を行う場合\")\nprint(\"pip install openai\")\nprint(\"\")\nprint(\"import openai\")\nprint(\"client = openai.OpenAI()\")\nprint(\"with open('audio.mp3', 'rb') as f:\")\nprint(\"    translation = client.audio.translations.create(\")\nprint(\"        model='whisper-1', file=f, response_format='text')\")\nprint(\"    print(translation)\")",
   "id": "129b4ec833bc0628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (6) 画像処理：Claude Vision",
   "id": "e70f5d237c7573cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T12:06:20.128112Z",
     "start_time": "2025-08-29T12:06:03.906825Z"
    }
   },
   "cell_type": "code",
   "source": "# Claude Vision - 画像解析機能\n# 注意: Anthropic APIには画像生成機能はありませんが、画像解析機能があります\nimport base64\nfrom anthropic import Anthropic\n\nclient = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n\n# 画像生成は外部サービスを使用する必要があります\nprint(\"注意: Anthropic APIには画像生成機能は含まれていません。\")\nprint(\"画像生成が必要な場合は、以下のようなサービスを利用してください：\")\nprint(\"- DALL-E (OpenAI)\")\nprint(\"- Midjourney\")\nprint(\"- Stable Diffusion\")\nprint(\"- Adobe Firefly\")\nprint(\"\")\n\n# 代わりに、画像解析の例を示します\nprint(\"Claude Vision - 画像解析の例:\")\nprint(\"\")\n\n# サンプル画像ファイルがある場合の解析例\nsample_image_path = \"data/sample_image.jpg\"  # プロジェクト内のサンプル画像があれば\n\nprint(f\"\"\"\n# 画像解析のサンプルコード:\ntry:\n    with open('{sample_image_path}', 'rb') as f:\n        image_data = base64.b64encode(f.read()).decode('utf-8')\n    \n    response = client.messages.create(\n        model=\"claude-3-5-sonnet-20241022\",\n        max_tokens=1000,\n        messages=[\n            {{\n                \"role\": \"user\",\n                \"content\": [\n                    {{\n                        \"type\": \"text\",\n                        \"text\": \"この画像について詳しく説明してください。\"\n                    }},\n                    {{\n                        \"type\": \"image\",\n                        \"source\": {{\n                            \"type\": \"base64\",\n                            \"media_type\": \"image/jpeg\",\n                            \"data\": image_data\n                        }}\n                    }}\n                ]\n            }}\n        ]\n    )\n    print(response.content[0].text)\nexcept FileNotFoundError:\n    print(\"画像ファイルが見つかりません。適切な画像パスを指定してください。\")\n\"\"\")",
   "id": "6f347e2daf1c46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (7) messages.create：詳細なメッセージ作成",
   "id": "2b621f5b204a9b63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T12:09:52.968552Z",
     "start_time": "2025-08-29T12:09:07.211105Z"
    }
   },
   "cell_type": "code",
   "source": "response = client.messages.create(\n    model=MODEL,\n    max_tokens=1000,\n    system=\"あなたは有能なPythonメンターです。\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Anthropic APIでJSONの構造化出力を行うには？\"},\n    ],\n    temperature=0.2\n)\n\nprint(response.content[0].text)",
   "id": "3bf94d92f1bcde7c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}