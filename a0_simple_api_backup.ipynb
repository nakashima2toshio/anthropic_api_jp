{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Anthropic API\",\n",
    "   \"id\": \"24aeb17d40f67591\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"initial_id\",\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": true\n",
    "   },\n",
    "   \"source\": \"# SetUp library\\n%pip install -U anthropic pydantic python-dotenv\\n\\nimport os, sys\\nimport anthropic\\n\\nprint(\\\"Python:\\\", sys.version)\\nprint(\\\"anthropic SDK:\\\", anthropic.__version__)\\nprint(\\\"Kernel:\\\", sys.executable)\\nprint(\\\"Has ANTHROPIC_API_KEY?:\\\", \\\"ANTHROPIC_API_KEY\\\" in os.environ)\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"# Check API_KEY\\nimport os\\n\\nprint(\\\"ANTHROPIC_API_KEY:\\\", os.environ.get(\\\"ANTHROPIC_API_KEY\\\", \\\"Not set\\\"))\",\n",
    "   \"id\": \"36bd637100865fb9\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### (1) messages.create：一般的な応答生成\",\n",
    "   \"id\": \"646bfa0ec3c1b3ad\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"prompt = \\\"\\\"\\\"以下の要件で簡潔に回答してください：\\n- 対象: Python学習者\\n- トピック: Anthropic APIのはじめ方\\n- 箇条書き3つ\\n\\\"\\\"\\\"\\nfrom anthropic import Anthropic\\n\\nclient = Anthropic(api_key=os.environ[\\\"ANTHROPIC_API_KEY\\\"])\\n\\nMODEL = \\\"claude-3-5-haiku-20241022\\\"\\n\\nresponse = client.messages.create(\\n    model=MODEL,\\n    max_tokens=1000,\\n    messages=[\\n        {\\\"role\\\": \\\"user\\\", \\\"content\\\": prompt}\\n    ]\\n)\\n\\nprint(response.content[0].text)  # テキスト抽出\",\n",
    "   \"id\": \"3113420afcad7f01\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### (2) 構造化出力（Pydantic with JSON Schema）\",\n",
    "   \"id\": \"c47b616f9e946fef\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"# 構造化出力（Pydantic）\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n\\nfrom anthropic import Anthropic\\nfrom pydantic import BaseModel, Field\\nfrom typing import List\\nimport json, os\\n\\nclient = Anthropic(api_key=os.getenv(\\\"ANTHROPIC_API_KEY\\\"))\\nMODEL = os.getenv(\\\"ANTHROPIC_MODEL\\\", \\\"claude-3-5-haiku-20241022\\\")\\n\\nclass TodoItem(BaseModel):\\n    title: str = Field(..., description=\\\"やることのタイトル\\\")\\n    priority: int = Field(..., ge=1, le=5, description=\\\"1(低)〜5(高)\\\")\\n    tags: List[str] = Field(default_factory=list)\\n\\nclass TodoPlan(BaseModel):\\n    owner: str\\n    items: List[TodoItem]\\n\\ninstruction = \\\"あなたは秘書です。日本語で、学習計画のToDoを構造化して返してください。\\\"\\nuser_text = \\\"明日はAnthropic APIを勉強、週末はQdrantを触る。優先度高いのは明日の学習。タグは['api','vector']\\\"\\n\\n# JSON Schemaを生成\\ndef to_json_schema(model_cls):\\n    if hasattr(model_cls, \\\"model_json_schema\\\"):\\n        return model_cls.model_json_schema()\\n    return model_cls.schema()\\n\\nschema = to_json_schema(TodoPlan)\\n\\n# Anthropic APIで構造化出力を生成\\nresponse = client.messages.create(\\n    model=MODEL,\\n    max_tokens=1000,\\n    messages=[\\n        {\\n            \\\"role\\\": \\\"user\\\", \\n            \\\"content\\\": f\\\"\\\"\\\"{instruction}\\n            \\nユーザー入力: {user_text}\\n\\n以下のJSONスキーマに厳密に従って、有効なJSONのみを出力してください：\\n{json.dumps(schema, ensure_ascii=False, indent=2)}\\n\\n必ずJSONのみを返し、説明やマークダウンは一切含めないでください。\\\"\\\"\\\"\\n        }\\n    ],\\n    temperature=0\\n)\\n\\n# JSONをパースしてPydanticモデルで検証\\ntry:\\n    json_text = response.content[0].text.strip()\\n    # マークダウンのコードブロックがある場合は除去\\n    if json_text.startswith('```json'):\\n        json_text = json_text.split('```json')[1].split('```')[0].strip()\\n    elif json_text.startswith('```'):\\n        json_text = json_text.split('```')[1].split('```')[0].strip()\\n    \\n    data = json.loads(json_text)\\n    parsed_plan = TodoPlan.model_validate(data)\\n    print(parsed_plan)\\nexcept (json.JSONDecodeError, ValueError) as e:\\n    print(f\\\"JSONパースエラー: {e}\\\")\\n    print(f\\\"生の応答: {response.content[0].text}\\\")\\nexcept Exception as e:\\n    print(f\\\"バリデーションエラー: {e}\\\")\\n    print(f\\\"パースされたデータ: {data}\\\")\",\n",
    "   \"id\": \"c4ceac3c38607d1b\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### (3) 注意：音声機能について\",\n",
    "   \"id\": \"73a2cadfa5361c32\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"# Anthropic APIには現在、音声生成機能（TTS）は含まれていません\\n# 音声機能が必要な場合は、以下のような代替手段を検討してください：\\n# 1. Google Cloud Text-to-Speech API\\n# 2. Azure Cognitive Services Speech\\n# 3. Amazon Polly\\n# 4. ElevenLabs API\\n\\nprint(\\\"注意: Anthropic APIには音声生成機能は含まれていません。\\\")\\nprint(\\\"音声機能が必要な場合は、専用の音声サービスを利用してください。\\\")\\nprint(\\\"\\\")\\nprint(\\\"例: Google Cloud Text-to-Speech APIの使用例\\\")\\nprint(\\\"pip install google-cloud-texttospeech\\\")\\nprint(\\\"\\\")\\nprint(\\\"from google.cloud import texttospeech\\\")\\nprint(\\\"client = texttospeech.TextToSpeechClient()\\\")\\nprint(\\\"# ... 音声生成処理\\\")\",\n",
    "   \"id\": \"775076638db71080\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### (4) 注意：音声認識機能について\",\n",
    "   \"id\": \"999422057e2fc3cb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"# Anthropic APIには現在、音声認識機能（STT）は含まれていません\\n# 音声認識が必要な場合は、以下のような代替手段を検討してください：\\n# 1. Google Cloud Speech-to-Text API\\n# 2. Azure Cognitive Services Speech\\n# 3. Amazon Transcribe\\n# 4. OpenAI Whisper API\\n\\nprint(\\\"注意: Anthropic APIには音声認識機能は含まれていません。\\\")\\nprint(\\\"音声認識が必要な場合は、専用の音声認識サービスを利用してください。\\\")\\nprint(\\\"\\\")\\nprint(\\\"例: Google Cloud Speech-to-Text APIの使用例\\\")\\nprint(\\\"pip install google-cloud-speech\\\")\\nprint(\\\"\\\")\\nprint(\\\"from google.cloud import speech\\\")\\nprint(\\\"client = speech.SpeechClient()\\\")\\nprint(\\\"# ... 音声認識処理\\\")\",\n",
    "   \"id\": \"3c3d6ba8d289e135\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### (5) 注意：音声翻訳機能について\",\n",
    "   \"id\": \"ac7feb09d78bba28\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Anthropic APIには現在、音声翻訳機能は含まれていません\\n\",\n",
    "    \"# 音声翻訳が必要な場合は、以下のような代替手段を検討してください：\\n\",\n",
    "    \"# 1. OpenAI Whisper API (音声→テキスト翻訳)\\n\",\n",
    "    \"# 2. Google Translate API + 音声認識API\\n\",\n",
    "    \"# 3. Azure Translator + 音声認識API\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"注意: Anthropic APIには音声翻訳機能は含まれていません。\\\")\\n\",\n",
    "    \"print(\\\"音声翻訳が必要な場合は、専用のサービスを利用してください。\\\")\\n\",\n",
    "    \"print(\\\"\\\")\\n\",\n",
    "    \"print(\\\"例: OpenAI Whisper APIで音声翻訳を行う場合\\\")\\n\",\n",
    "    \"print(\\\"pip install openai\\\")\\n\",\n",
    "    \"print(\\\"\\\")\\n\",\n",
    "    \"print(\\\"import openai\\\")\\n\",\n",
    "    \"print(\\\"client = openai.OpenAI()\\\")\\n\",\n",
    "    \"print(\\\"with open('audio.mp3', 'rb') as f:\\\")\\n\",\n",
    "    \"print(\\\"    translation = client.audio.translations.create(\\\")\\n\",\n",
    "    \"print(\\\"        model='whisper-1', file=f, response_format='text')\\\")\\n\",\n",
    "    \"print(\\\"    print(translation)\\\")\"\n",
    "   ],\n",
    "   \"id\": \"eafff49017fb90c8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### (6) 画像処理：Claude Vision\",\n",
    "   \"id\": \"e70f5d237c7573cc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": \"# Claude Vision - 画像解析機能\\n# 注意: Anthropic APIには画像生成機能はありませんが、画像解析機能があります\\nimport base64\\nfrom anthropic import Anthropic\\n\\nclient = Anthropic(api_key=os.environ[\\\"ANTHROPIC_API_KEY\\\"])\\n\\n# 画像生成は外部サービスを使用する必要があります\\nprint(\\\"注意: Anthropic APIには画像生成機能は含まれていません。\\\")\\nprint(\\\"画像生成が必要な場合は、以下のようなサービスを利用してください：\\\")\\nprint(\\\"- DALL-E (OpenAI)\\\")\\nprint(\\\"- Midjourney\\\")\\nprint(\\\"- Stable Diffusion\\\")\\nprint(\\\"- Adobe Firefly\\\")\\nprint(\\\"\\\")\\n\\n# 代わりに、画像解析の例を示します\\nprint(\\\"Claude Vision - 画像解析の例:\\\")\\nprint(\\\"\\\")\\n\\n# サンプル画像ファイル（5MB制限内のファイルを使用）\\nsample_image_path = \\\"images/bmetal.png\\\"  # 134KB - 5MB制限内\\n\\n# 画像解析のサンプルコード:\\ntry:\\n    with open(sample_image_path, 'rb') as f:\\n        image_data = base64.b64encode(f.read()).decode('utf-8')\\n    \\n    response = client.messages.create(\\n        model=\\\"claude-3-5-sonnet-20241125\\\",  # より新しいモデルを使用\\n        max_tokens=1000,\\n        messages=[\\n            {\\n                \\\"role\\\": \\\"user\\\",\\n                \\\"content\\\": [\\n                    {\\n                        \\\"type\\\": \\\"text\\\",\\n                        \\\"text\\\": \\\"この画像について詳しく説明してください。\\\"\\n                    },\\n                    {\\n                        \\\"type\\\": \\\"image\\\",\\n                        \\\"source\\\": {\\n                            \\\"type\\\": \\\"base64\\\",\\n                            \\\"media_type\\\": \\\"image/png\\\",\\n                            \\\"data\\\": image_data\\n                        }\\n                    }\\n                ]\\n            }\\n        ]\\n    )\\n    print(response.content[0].text)\\nexcept FileNotFoundError:\\n    print(\\\"画像ファイルが見つかりません。適切な画像パスを指定してください。\\\")\\nexcept Exception as e:\\n    print(f\\\"エラーが発生しました: {e}\\\")\",\n",
    "   \"id\": \"f0e0f7312d2a529c\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### (7) messages.create：詳細なメッセージ作成\",\n",
    "   \"id\": \"3fbcdaac6288cea5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"response = client.messages.create(\\n\",\n",
    "    \"    model=MODEL,\\n\",\n",
    "    \"    max_tokens=1000,\\n\",\n",
    "    \"    system=\\\"あなたは有能なPythonメンターです。\\\",\\n\",\n",
    "    \"    messages=[\\n\",\n",
    "    \"        {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Anthropic APIでJSONの構造化出力を行うには？\\\"},\\n\",\n",
    "    \"    ],\\n\",\n",
    "    \"    temperature=0.2\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(response.content[0].text)\"\n",
    "   ],\n",
    "   \"id\": \"bb42423214cf4915\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "17217398ead15234",
   "outputs": null,
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "# SetUp library\n%pip install -U anthropic pydantic python-dotenv\n\nimport os, sys\nimport anthropic\n\nprint(\"Python:\", sys.version)\nprint(\"anthropic SDK:\", anthropic.__version__)\nprint(\"Kernel:\", sys.executable)\nprint(\"Has ANTHROPIC_API_KEY?:\", \"ANTHROPIC_API_KEY\" in os.environ)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Check API_KEY\nimport os\n\nprint(\"ANTHROPIC_API_KEY:\", os.environ.get(\"ANTHROPIC_API_KEY\", \"Not set\"))",
   "id": "36bd637100865fb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (1) messages.create：一般的な応答生成",
   "id": "646bfa0ec3c1b3ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt = \"\"\"以下の要件で簡潔に回答してください：\n- 対象: Python学習者\n- トピック: Anthropic APIのはじめ方\n- 箇条書き3つ\n\"\"\"\nfrom anthropic import Anthropic\n\nclient = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n\nMODEL = \"claude-3-5-haiku-20241022\"\n\nresponse = client.messages.create(\n    model=MODEL,\n    max_tokens=1000,\n    messages=[\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n)\n\nprint(response.content[0].text)  # テキスト抽出",
   "id": "3113420afcad7f01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (2) 構造化出力（Pydantic with JSON Schema）",
   "id": "c47b616f9e946fef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# 構造化出力（Pydantic）\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport json, os\n\nclient = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\nMODEL = os.getenv(\"ANTHROPIC_MODEL\", \"claude-3-5-haiku-20241022\")\n\nclass TodoItem(BaseModel):\n    title: str = Field(..., description=\"やることのタイトル\")\n    priority: int = Field(..., ge=1, le=5, description=\"1(低)〜5(高)\")\n    tags: List[str] = Field(default_factory=list)\n\nclass TodoPlan(BaseModel):\n    owner: str\n    items: List[TodoItem]\n\ninstruction = \"あなたは秘書です。日本語で、学習計画のToDoを構造化して返してください。\"\nuser_text = \"明日はAnthropic APIを勉強、週末はQdrantを触る。優先度高いのは明日の学習。タグは['api','vector']\"\n\n# JSON Schemaを生成\ndef to_json_schema(model_cls):\n    if hasattr(model_cls, \"model_json_schema\"):\n        return model_cls.model_json_schema()\n    return model_cls.schema()\n\nschema = to_json_schema(TodoPlan)\n\n# Anthropic APIで構造化出力を生成\nresponse = client.messages.create(\n    model=MODEL,\n    max_tokens=1000,\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": f\"\"\"{instruction}\n            \nユーザー入力: {user_text}\n\n以下のJSONスキーマに厳密に従って、有効なJSONのみを出力してください：\n{json.dumps(schema, ensure_ascii=False, indent=2)}\n\n必ずJSONのみを返し、説明やマークダウンは一切含めないでください。\"\"\"\n        }\n    ],\n    temperature=0\n)\n\n# JSONをパースしてPydanticモデルで検証\ntry:\n    json_text = response.content[0].text.strip()\n    # マークダウンのコードブロックがある場合は除去\n    if json_text.startswith('```json'):\n        json_text = json_text.split('```json')[1].split('```')[0].strip()\n    elif json_text.startswith('```'):\n        json_text = json_text.split('```')[1].split('```')[0].strip()\n    \n    data = json.loads(json_text)\n    parsed_plan = TodoPlan.model_validate(data)\n    print(parsed_plan)\nexcept (json.JSONDecodeError, ValueError) as e:\n    print(f\"JSONパースエラー: {e}\")\n    print(f\"生の応答: {response.content[0].text}\")\nexcept Exception as e:\n    print(f\"バリデーションエラー: {e}\")\n    print(f\"パースされたデータ: {data}\")",
   "id": "c4ceac3c38607d1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (3) 注意：音声機能について",
   "id": "73a2cadfa5361c32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Anthropic APIには現在、音声生成機能（TTS）は含まれていません\n# 音声機能が必要な場合は、以下のような代替手段を検討してください：\n# 1. Google Cloud Text-to-Speech API\n# 2. Azure Cognitive Services Speech\n# 3. Amazon Polly\n# 4. ElevenLabs API\n\nprint(\"注意: Anthropic APIには音声生成機能は含まれていません。\")\nprint(\"音声機能が必要な場合は、専用の音声サービスを利用してください。\")\nprint(\"\")\nprint(\"例: Google Cloud Text-to-Speech APIの使用例\")\nprint(\"pip install google-cloud-texttospeech\")\nprint(\"\")\nprint(\"from google.cloud import texttospeech\")\nprint(\"client = texttospeech.TextToSpeechClient()\")\nprint(\"# ... 音声生成処理\")",
   "id": "775076638db71080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (4) 注意：音声認識機能について",
   "id": "999422057e2fc3cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Anthropic APIには現在、音声認識機能（STT）は含まれていません\n# 音声認識が必要な場合は、以下のような代替手段を検討してください：\n# 1. Google Cloud Speech-to-Text API\n# 2. Azure Cognitive Services Speech\n# 3. Amazon Transcribe\n# 4. OpenAI Whisper API\n\nprint(\"注意: Anthropic APIには音声認識機能は含まれていません。\")\nprint(\"音声認識が必要な場合は、専用の音声認識サービスを利用してください。\")\nprint(\"\")\nprint(\"例: Google Cloud Speech-to-Text APIの使用例\")\nprint(\"pip install google-cloud-speech\")\nprint(\"\")\nprint(\"from google.cloud import speech\")\nprint(\"client = speech.SpeechClient()\")\nprint(\"# ... 音声認識処理\")",
   "id": "3c3d6ba8d289e135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (5) 注意：音声翻訳機能について",
   "id": "ac7feb09d78bba28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Anthropic APIには現在、音声翻訳機能は含まれていません\n",
    "# 音声翻訳が必要な場合は、以下のような代替手段を検討してください：\n",
    "# 1. OpenAI Whisper API (音声→テキスト翻訳)\n",
    "# 2. Google Translate API + 音声認識API\n",
    "# 3. Azure Translator + 音声認識API\n",
    "\n",
    "print(\"注意: Anthropic APIには音声翻訳機能は含まれていません。\")\n",
    "print(\"音声翻訳が必要な場合は、専用のサービスを利用してください。\")\n",
    "print(\"\")\n",
    "print(\"例: OpenAI Whisper APIで音声翻訳を行う場合\")\n",
    "print(\"pip install openai\")\n",
    "print(\"\")\n",
    "print(\"import openai\")\n",
    "print(\"client = openai.OpenAI()\")\n",
    "print(\"with open('audio.mp3', 'rb') as f:\")\n",
    "print(\"    translation = client.audio.translations.create(\")\n",
    "print(\"        model='whisper-1', file=f, response_format='text')\")\n",
    "print(\"    print(translation)\")"
   ],
   "id": "eafff49017fb90c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (6) 画像処理：Claude Vision",
   "id": "e70f5d237c7573cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Claude Vision - 画像解析機能\n# 注意: Anthropic APIには画像生成機能はありませんが、画像解析機能があります\nimport base64\nfrom anthropic import Anthropic\n\nclient = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n\n# 画像生成は外部サービスを使用する必要があります\nprint(\"注意: Anthropic APIには画像生成機能は含まれていません。\")\nprint(\"画像生成が必要な場合は、以下のようなサービスを利用してください：\")\nprint(\"- DALL-E (OpenAI)\")\nprint(\"- Midjourney\")\nprint(\"- Stable Diffusion\")\nprint(\"- Adobe Firefly\")\nprint(\"\")\n\n# 代わりに、画像解析の例を示します\nprint(\"Claude Vision - 画像解析の例:\")\nprint(\"\")\n\n# サンプル画像ファイル（5MB制限内のファイルを使用）\nsample_image_path = \"images/bmetal.png\"  # 134KB - 5MB制限内\n\n# 画像解析のサンプルコード:\ntry:\n    with open(sample_image_path, 'rb') as f:\n        image_data = base64.b64encode(f.read()).decode('utf-8')\n    \n    response = client.messages.create(\n        model=\"claude-3-5-sonnet-20241125\",  # より新しいモデルを使用\n        max_tokens=1000,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"この画像について詳しく説明してください。\"\n                    },\n                    {\n                        \"type\": \"image\",\n                        \"source\": {\n                            \"type\": \"base64\",\n                            \"media_type\": \"image/png\",\n                            \"data\": image_data\n                        }\n                    }\n                ]\n            }\n        ]\n    )\n    print(response.content[0].text)\nexcept FileNotFoundError:\n    print(\"画像ファイルが見つかりません。適切な画像パスを指定してください。\")\nexcept Exception as e:\n    print(f\"エラーが発生しました: {e}\")",
   "id": "f0e0f7312d2a529c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (7) messages.create：詳細なメッセージ作成",
   "id": "3fbcdaac6288cea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = client.messages.create(\n",
    "    model=MODEL,\n",
    "    max_tokens=1000,\n",
    "    system=\"あなたは有能なPythonメンターです。\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Anthropic APIでJSONの構造化出力を行うには？\"},\n",
    "    ],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "print(response.content[0].text)"
   ],
   "id": "bb42423214cf4915",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
